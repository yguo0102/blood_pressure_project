{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1782cc89-6598-4126-8535-f2d67249d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the evaluation metrics\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "# git clone https://github.com/davidsbatista/NER-Evaluation\n",
    "import NER_Evaluation.ner_evaluation.ner_eval\n",
    "from NER_Evaluation.ner_evaluation.ner_eval import collect_named_entities\n",
    "from NER_Evaluation.ner_evaluation.ner_eval import compute_metrics\n",
    "from NER_Evaluation.ner_evaluation.ner_eval import compute_precision_recall_wrapper\n",
    "targets = [\n",
    "'N_male',\n",
    "'N_female',\n",
    "'SBP_in_male_mean',\n",
    "'SBP_in_female_mean',\n",
    "'SBP_in_male_std',\n",
    "'SBP_in_female_std',\n",
    "'DBP_in_male_mean',\n",
    "'DBP_in_female_mean',\n",
    "'DBP_in_male_std',\n",
    "'DBP_in_female_std'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e22362c-f065-4d5c-bfb7-62ba55cf3adb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 86 27\n"
     ]
    }
   ],
   "source": [
    "# Read the test set with groudtruth.\n",
    "import pandas as pd\n",
    "\n",
    "label_file = 'test.txt'\n",
    "labels = [[]]\n",
    "with open(label_file) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            labels.append([])\n",
    "        else:\n",
    "            _, label = line.split()\n",
    "            label = label.replace('E-', 'I-').replace('S-', 'B-') # use BIO format\n",
    "            labels[-1].append(label)\n",
    "if len(labels[-1]) == 0:\n",
    "    labels = labels[:-1]\n",
    "print(len(labels), len(labels[0]), len(labels[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafc102b-deae-4132-b5fe-e499c2886202",
   "metadata": {},
   "source": [
    "# Read few shot/DANN predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "552adecf-3a94-4fe7-b5a0-87c8e3f4a318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 86 27\n"
     ]
    }
   ],
   "source": [
    "# Read the predictions from a few shot model.\n",
    "fewShot_pred_file = 'predictions-bp-pred.txt'\n",
    "fewShot_preds = []\n",
    "with open(fewShot_pred_file) as f:\n",
    "    for line in f:\n",
    "        preds = line.strip().split()\n",
    "        preds = [x.replace('E-', 'I-').replace('S-', 'B-') for x in preds]\n",
    "        fewShot_preds.append(preds)\n",
    "print(len(fewShot_preds), len(fewShot_preds[0]), len(fewShot_preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d8cf56-af82-4341-a469-4754c4c4883a",
   "metadata": {},
   "source": [
    "# Read LLM predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10f723fa-fb96-4b5d-b07a-3777f7b8d82b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pmc_s', 'text', 'N_male', 'N_female', 'SBP_in_male_mean',\n",
      "       'SBP_in_female_mean', 'SBP_in_male_std', 'SBP_in_female_std',\n",
      "       'DBP_in_male_mean', 'DBP_in_female_mean', 'DBP_in_male_std',\n",
      "       'DBP_in_female_std', 'Notes', 'positive_case', 'full_prompt',\n",
      "       'response', 'bp_male_mean', 'bp_female_mean', 'bp_male_std',\n",
      "       'bp_female_std', 'pred'],\n",
      "      dtype='object')\n",
      "[13, 4, 2, 18, 21, 16, 11, 7, 15, 17, 8, 22, 14, 5, 6, 20, 1, 3, 12, 10, 0, 9, 19]\n"
     ]
    }
   ],
   "source": [
    "#!pip install openpyxl\n",
    "llm_pred_file = '/labs/sarkerlab/yguo262/blood_pressure_project/LLM/datasets/ann_050724_new/test.gpt35.xlsx'\n",
    "llm_df = pd.read_excel(llm_pred_file)\n",
    "print(llm_df.columns)\n",
    "\n",
    "docID_order = pd.read_excel('bp_test_fewshot_results.xlsm', sheet_name='prediction_DANN')['pmc_s'].values.tolist()\n",
    "new_index = [0] * len(docID_order)\n",
    "for i, row in llm_df.iterrows():\n",
    "    for j, docID in enumerate(docID_order):\n",
    "        if row['pmc_s'] == docID:\n",
    "            new_index[j] = i\n",
    "print(new_index)\n",
    "llm_df = llm_df.iloc[new_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0de0e2bc-c3e6-47ea-ae61-67522f9053dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 86 27\n"
     ]
    }
   ],
   "source": [
    "# Convert LLM output into BIO format\n",
    "#!pip install nltk\n",
    "from nltk.tokenize import wordpunct_tokenize, sent_tokenize\n",
    "\n",
    "def list_match(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != b[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_target(long_list, short_list):\n",
    "    for i in range(len(long_list)-len(short_list)):\n",
    "        same_li = list_match(long_list[i:i+len(short_list)], short_list)\n",
    "        if same_li:\n",
    "            return i\n",
    "    return -1\n",
    "    \n",
    "def conv_to_BIO(df):\n",
    "    BIO_preds = [[]]\n",
    "    for _, row in df.iterrows():\n",
    "        label = row['positive_case']\n",
    "        text = row['text'].strip()\n",
    "        sentences = sent_tokenize(text)\n",
    "        all_tokens = [wordpunct_tokenize(sentence) for sentence in sentences]            \n",
    "        all_target_tokens = [wordpunct_tokenize(str(row[target]).replace('.0', '')) for target in targets]\n",
    "        \n",
    "        if label:\n",
    "            match_count = 0\n",
    "            for tokens in all_tokens:\n",
    "                pos_map = {}\n",
    "                for k, target_tokens in enumerate(all_target_tokens):\n",
    "                    start_pos = find_target(tokens, target_tokens)\n",
    "                    if start_pos >= 0:\n",
    "                        match_count += 1\n",
    "                        for pos in range(start_pos, start_pos+len(target_tokens)):\n",
    "                            if pos == start_pos:\n",
    "                                pos_map[pos] = 'B-' + targets[k]\n",
    "                            else:\n",
    "                                pos_map[pos] = 'I-' + targets[k]\n",
    "\n",
    "                for k, token in enumerate(tokens):\n",
    "                    if k in pos_map:\n",
    "                        BIO_preds[-1].append(pos_map[k])\n",
    "                    else:\n",
    "                        BIO_preds[-1].append('O')\n",
    "                BIO_preds.append([])            \n",
    "        else:\n",
    "            for tokens in all_tokens:\n",
    "                for token in tokens:\n",
    "                    BIO_preds[-1].append('O')    \n",
    "                BIO_preds.append([])\n",
    "    return BIO_preds\n",
    "\n",
    "llm_preds = conv_to_BIO(llm_df)\n",
    "if len(llm_preds[-1]) == 0:\n",
    "    llm_preds = llm_preds[:-1]\n",
    "print(len(llm_preds), len(llm_preds[0]), len(llm_preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f0a77b3-6dfb-4623-9867-cf2d1e4444f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(gold_labels, pred_labels):\n",
    "    \n",
    "    metrics_results = {'correct': 0, 'incorrect': 0, 'partial': 0,\n",
    "                       'missed': 0, 'spurious': 0, 'possible': 0, 'actual': 0, 'precision': 0, 'recall': 0}\n",
    "    \n",
    "    # overall results\n",
    "    results = {'strict': deepcopy(metrics_results),\n",
    "               'ent_type': deepcopy(metrics_results),\n",
    "               'partial':deepcopy(metrics_results),\n",
    "               'exact':deepcopy(metrics_results)\n",
    "              }\n",
    "    \n",
    "    # results aggregated by entity type\n",
    "    evaluation_agg_entities_type = {e: deepcopy(results) for e in targets}\n",
    "    \n",
    "    for true_ents, pred_ents in zip(gold_labels, pred_labels):\n",
    "    \n",
    "        # compute results for one message\n",
    "        tmp_results, tmp_agg_results = compute_metrics(\n",
    "            collect_named_entities(true_ents), collect_named_entities(pred_ents),  targets\n",
    "        )\n",
    "        #print(tmp_results)\n",
    "    \n",
    "        # aggregate overall results\n",
    "        for eval_schema in results.keys():\n",
    "            for metric in metrics_results.keys():\n",
    "                results[eval_schema][metric] += tmp_results[eval_schema][metric]\n",
    "    \n",
    "        # Calculate global precision and recall\n",
    "        #print(results)\n",
    "        results = compute_precision_recall_wrapper(results)\n",
    "    \n",
    "    \n",
    "        # aggregate results by entity type\n",
    "    \n",
    "        for e_type in targets:\n",
    "    \n",
    "            for eval_schema in tmp_agg_results[e_type]:\n",
    "    \n",
    "                for metric in tmp_agg_results[e_type][eval_schema]:\n",
    "    \n",
    "                    evaluation_agg_entities_type[e_type][eval_schema][metric] += tmp_agg_results[e_type][eval_schema][metric]\n",
    "    \n",
    "            # Calculate precision recall at the individual entity level\n",
    "    \n",
    "            evaluation_agg_entities_type[e_type] = compute_precision_recall_wrapper(evaluation_agg_entities_type[e_type])\n",
    "    return results, evaluation_agg_entities_type\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7c43444-7714-4472-b8a8-1cd13879d1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ent_type': {'correct': 16, 'incorrect': 11, 'partial': 0, 'missed': 50, 'spurious': 15, 'possible': 77, 'actual': 42, 'precision': 0.38095238095238093, 'recall': 0.2077922077922078}, 'partial': {'correct': 27, 'incorrect': 0, 'partial': 0, 'missed': 50, 'spurious': 15, 'possible': 77, 'actual': 42, 'precision': 0.6428571428571429, 'recall': 0.35064935064935066}, 'strict': {'correct': 16, 'incorrect': 11, 'partial': 0, 'missed': 50, 'spurious': 15, 'possible': 77, 'actual': 42, 'precision': 0.38095238095238093, 'recall': 0.2077922077922078}, 'exact': {'correct': 27, 'incorrect': 0, 'partial': 0, 'missed': 50, 'spurious': 15, 'possible': 77, 'actual': 42, 'precision': 0.6428571428571429, 'recall': 0.35064935064935066}} {'ent_type': {'correct': 40, 'incorrect': 0, 'partial': 0, 'missed': 37, 'spurious': 4, 'possible': 77, 'actual': 44, 'precision': 0.9090909090909091, 'recall': 0.5194805194805194}, 'partial': {'correct': 40, 'incorrect': 0, 'partial': 0, 'missed': 37, 'spurious': 4, 'possible': 77, 'actual': 44, 'precision': 0.9090909090909091, 'recall': 0.5194805194805194}, 'strict': {'correct': 40, 'incorrect': 0, 'partial': 0, 'missed': 37, 'spurious': 4, 'possible': 77, 'actual': 44, 'precision': 0.9090909090909091, 'recall': 0.5194805194805194}, 'exact': {'correct': 40, 'incorrect': 0, 'partial': 0, 'missed': 37, 'spurious': 4, 'possible': 77, 'actual': 44, 'precision': 0.9090909090909091, 'recall': 0.5194805194805194}}\n"
     ]
    }
   ],
   "source": [
    "# Compute the metrics\n",
    "fewShot_results, fewShot_evaluation_agg_entities_type = compute(labels, fewShot_preds)\n",
    "llm_results, llm_evaluation_agg_entities_type = compute(labels, llm_preds)\n",
    "print(fewShot_results, llm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afe1e59c-6d28-446b-aae5-638659c2841d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varible</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N_male</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N_female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBP_in_male_mean</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBP_in_female_mean</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBP_in_male_std</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SBP_in_female_std</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DBP_in_male_mean</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DBP_in_female_mean</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DBP_in_male_std</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DBP_in_female_std</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              varible  precision    recall         f\n",
       "0              N_male   0.200000  0.500000  0.285714\n",
       "1            N_female   0.000000  0.000000  0.000000\n",
       "2    SBP_in_male_mean   0.100000  0.250000  0.142857\n",
       "3  SBP_in_female_mean   0.250000  0.625000  0.357143\n",
       "4     SBP_in_male_std   0.117647  0.333333  0.173913\n",
       "5   SBP_in_female_std   0.000000  0.000000  0.000000\n",
       "6    DBP_in_male_mean   0.055556  0.125000  0.076923\n",
       "7  DBP_in_female_mean   0.062500  0.125000  0.083333\n",
       "8     DBP_in_male_std   0.062500  0.200000  0.095238\n",
       "9   DBP_in_female_std   0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_f1(p, r):\n",
    "    return 2*p*r/(p+r) if p+r != 0 else 0\n",
    "    \n",
    "def fmt_agg_entities(evaluation_agg_entities_type, metric='ent_type'):\n",
    "    # Print in a format good for excel\n",
    "    output = pd.DataFrame({'varible':[], 'precision':[], 'recall':[], 'f':[]})\n",
    "    for target in targets:\n",
    "        p = evaluation_agg_entities_type[target][metric]['precision']\n",
    "        r = evaluation_agg_entities_type[target][metric]['recall']\n",
    "        f = 0 if p+r == 0 else get_f1(p, r)\n",
    "        output.loc[len(output)] = (target, p, r, f)\n",
    "    return output\n",
    "output = fmt_agg_entities(fewShot_evaluation_agg_entities_type)\n",
    "output.to_excel('fewshot_result.xlsx')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e28a382-787f-46f7-b40a-7751adcdbd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varible</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N_male</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N_female</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBP_in_male_mean</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBP_in_female_mean</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBP_in_male_std</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SBP_in_female_std</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DBP_in_male_mean</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DBP_in_female_mean</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DBP_in_male_std</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DBP_in_female_std</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              varible  precision    recall         f\n",
       "0              N_male   0.500000  0.500000  0.500000\n",
       "1            N_female   0.500000  0.444444  0.470588\n",
       "2    SBP_in_male_mean   0.500000  0.500000  0.500000\n",
       "3  SBP_in_female_mean   0.500000  0.500000  0.500000\n",
       "4     SBP_in_male_std   0.500000  0.666667  0.571429\n",
       "5   SBP_in_female_std   0.555556  0.555556  0.555556\n",
       "6    DBP_in_male_mean   0.500000  0.500000  0.500000\n",
       "7  DBP_in_female_mean   0.500000  0.500000  0.500000\n",
       "8     DBP_in_male_std   0.428571  0.600000  0.500000\n",
       "9   DBP_in_female_std   0.500000  0.500000  0.500000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = fmt_agg_entities(llm_evaluation_agg_entities_type)\n",
    "output.to_excel('llm_result.xlsx')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7cd46f47-3e5d-46d9-bdfc-3a1ff9dabed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 4, 2, 18, 21, 16, 11, 7, 15, 17, 8, 22, 14, 5, 6, 20, 1, 3, 12, 10, 0, 9, 19]\n",
      "74 86 27\n",
      "gpt35\t0.9090909090909091\t0.5194805194805194\t0.6611570247933884\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LLM in batch\n",
    "#!pip install openpyxl\n",
    "\n",
    "docID_order = pd.read_excel('bp_test_fewshot_results.xlsm', sheet_name='prediction_DANN')['pmc_s'].values.tolist()\n",
    "new_index = [0] * len(docID_order)\n",
    "for i, row in llm_df.iterrows():\n",
    "    for j, docID in enumerate(docID_order):\n",
    "        if row['pmc_s'] == docID:\n",
    "            new_index[j] = i\n",
    "print(new_index)\n",
    "\n",
    "for model in ['gpt35']:\n",
    "    llm_pred_file = f'/labs/sarkerlab/yguo262/blood_pressure_project/LLM/datasets/ann_050724_new/test.{model}.xlsx'\n",
    "    llm_df = pd.read_excel(llm_pred_file)\n",
    "    llm_df = llm_df.iloc[new_index]\n",
    "    \n",
    "    llm_preds = conv_to_BIO(llm_df)\n",
    "    if len(llm_preds[-1]) == 0:\n",
    "        llm_preds = llm_preds[:-1]\n",
    "    print(len(llm_preds), len(llm_preds[0]), len(llm_preds[1]))\n",
    "\n",
    "    llm_results, llm_evaluation_agg_entities_type = compute(labels, llm_preds)\n",
    "    precision = llm_results['ent_type']['precision']\n",
    "    recall = llm_results['ent_type']['recall']\n",
    "    f = get_f1(precision, recall)\n",
    "    print(f'{model}\\t{precision}\\t{recall}\\t{f}')\n",
    "    output = fmt_agg_entities(llm_evaluation_agg_entities_type, metric='ent_type')\n",
    "    output.to_excel(f'llm_result.{model}.xlsx')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
